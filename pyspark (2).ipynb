{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e509ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce32b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bb5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Sample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f8b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x186ff503a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54e0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365abb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8914c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a57141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: string, Experience: string, Salary: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e870f523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8490e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    suraj| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fae7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18db923a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='suraj', age='31', Experience='10', Salary='30000'),\n",
       " Row(Name='Sudhanshu', age='30', Experience='8', Salary='25000'),\n",
       " Row(Name='Sunny', age='29', Experience='4', Salary='20000')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b02b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     Name|Experience|\n",
      "+---------+----------+\n",
      "|    suraj|        10|\n",
      "|Sudhanshu|         8|\n",
      "|    Sunny|         4|\n",
      "|     Paul|         3|\n",
      "|   Harsha|         1|\n",
      "|  Shubham|         2|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select([\"Name\",\"Experience\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff2b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+------------------+\n",
      "|summary|  Name|               age|       Experience|            Salary|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "|  count|     6|                 6|                6|                 6|\n",
      "|   mean|  NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n",
      "| stddev|  NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
      "|    min|Harsha|                21|                1|             15000|\n",
      "|    max| suraj|                31|                8|             30000|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b193d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark1 = spark.read.csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3be7effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark1 = spark.read.option('header','true').csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bba8e16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: string, Experience: string, Salary: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c291fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "| New Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.withColumnRenamed(\"Name\",\"New Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac641e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63e52011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1159d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7980a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     NULL| 34|        10| 38000|\n",
      "|     NULL| 36|      NULL|  NULL|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.drop(how=\"any\",subset=[\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b7940b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.drop(how=\"any\",subset=[\"Name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8b7039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|   missing| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|   missing|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill(\"missing\",[\"Experience\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c99c9659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------+------+\n",
      "|     Name|    age|Experience|Salary|\n",
      "+---------+-------+----------+------+\n",
      "|    Krish|     31|        10| 30000|\n",
      "|Sudhanshu|     30|         8| 25000|\n",
      "|    Sunny|     29|         4| 20000|\n",
      "|     Paul|     24|         3| 20000|\n",
      "|   Harsha|     21|         1| 15000|\n",
      "|  Shubham|     23|         2| 18000|\n",
      "|   Mahesh|missing|   missing| 40000|\n",
      "|     NULL|     34|        10| 38000|\n",
      "|     NULL|     36|   missing|  NULL|\n",
      "+---------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill(\"missing\",[\"age\",\"Experience\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa7ccb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+------+\n",
      "|     Name|          age|   Experience|Salary|\n",
      "+---------+-------------+-------------+------+\n",
      "|    Krish|           31|           10| 30000|\n",
      "|Sudhanshu|           30|            8| 25000|\n",
      "|    Sunny|           29|            4| 20000|\n",
      "|     Paul|           24|            3| 20000|\n",
      "|   Harsha|           21|            1| 15000|\n",
      "|  Shubham|           23|            2| 18000|\n",
      "|   Mahesh|missing value|missing value| 40000|\n",
      "|     NULL|           34|           10| 38000|\n",
      "|     NULL|           36|missing value|  NULL|\n",
      "+---------+-------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill(\"missing value\",[\"Experience\",\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45280a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+-------------+\n",
      "|         Name|          age|   Experience|       Salary|\n",
      "+-------------+-------------+-------------+-------------+\n",
      "|        Krish|           31|           10|        30000|\n",
      "|    Sudhanshu|           30|            8|        25000|\n",
      "|        Sunny|           29|            4|        20000|\n",
      "|         Paul|           24|            3|        20000|\n",
      "|       Harsha|           21|            1|        15000|\n",
      "|      Shubham|           23|            2|        18000|\n",
      "|       Mahesh|missing value|missing value|        40000|\n",
      "|missing value|           34|           10|        38000|\n",
      "|missing value|           36|missing value|missing value|\n",
      "+-------------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.na.fill(\"missing value\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7ed609b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('age', 'string'),\n",
       " ('Experience', 'string'),\n",
       " ('Salary', 'string')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "791084e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+---------------+\n",
      "|     Name|age|Experience|Salary|exp after 10 yr|\n",
      "+---------+---+----------+------+---------------+\n",
      "|    suraj| 31|        10| 30000|           20.0|\n",
      "|Sudhanshu| 30|         8| 25000|           18.0|\n",
      "|    Sunny| 29|         4| 20000|           14.0|\n",
      "|     Paul| 24|         3| 20000|           13.0|\n",
      "|   Harsha| 21|         1| 15000|           11.0|\n",
      "|  Shubham| 23|         2| 18000|           12.0|\n",
      "+---------+---+----------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=df_pyspark.withColumn(\"exp after 10 yr\",df_pyspark[\"Experience\"]+10)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b44c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    suraj| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=df_pyspark.drop(\"exp after 10 yr\")\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d20e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df_pyspark1.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dae5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43701673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc428b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      35000|\n",
      "|    Sunny|      12000|\n",
      "|    Krish|      19000|\n",
      "|   Mahesh|       7000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0940abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     Name|       avg(salary)|\n",
      "+---------+------------------+\n",
      "|Sudhanshu|11666.666666666666|\n",
      "|    Sunny|            6000.0|\n",
      "|    Krish| 6333.333333333333|\n",
      "|   Mahesh|            3500.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43115abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      15000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bdd6172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "941b0379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9181458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ebbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
